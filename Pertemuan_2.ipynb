{"nbformat":4,"nbformat_minor":0,"metadata":{"celltoolbar":"Slideshow","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"Pertemuan_2.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"vBefyd6UGdgx"},"source":["<center><strong>Sistem Temu Kembali Informasi</strong><br />\n","<strong><font color=\"blue\">Semester Gasal T.A. 2020/2021</font></strong><br />\n","</center>\n","\n","<strong>Outline pertemuan minggu ke-2</strong><br />\n","<li> Tokenisasi </li>\n","<li> Casefolding </li>\n","<li> Stemming dan Lemmatization</li>\n","<li> Part of Speech (POS) tagging </li>\n","<li> Stopword removal </li>\n","\n"]},{"cell_type":"markdown","metadata":{"id":"nbO33SmcGdhA"},"source":["## Tokenisasi\n","\n","<p>Tokenisasi adalah pemisahan kata, simbol, frase, dan entitas penting lainnya (yang disebut sebagai token) dari sebuah teks untuk kemudian di analisa lebih lanjut. Token dalam NLP sering dimaknai dengan &quot;sebuah kata&quot;, walau tokenisasi juga bisa dilakukan ke kalimat, paragraf, atau entitas penting lainnya (misal suatu pola string DNA di Bioinformatika).</p>\n","\n","<p><strong>Mengapa perlu tokenisasi?</strong></p>\n","\n","<ul>\n","\t<li>Langkah penting dalam preprocessing, menghindari kompleksitas mengolah langsung pada string asal.</li>\n","\t<li>Menghindari masalah (semantic) saat pemrosesan model-model natural language.</li>\n","\t<li>Suatu tahapan sistematis dalam merubah unstructured (text) data ke bentuk terstruktur yang lebih mudah di olah.</li>\n","</ul>\n","\n","<p><img alt=\"\" src=\"figures\\2_Pipeline_Tokenization.png\" style=\"height:300px; width:768px\" /><br />\n","[<a href=\"https://www.softwareadvice.com/resources/what-is-text-analytics/\" target=\"_blank\"><strong>Image Source</strong></a>]</p>\n"]},{"cell_type":"markdown","metadata":{"id":"T8xbYn0cGdhC"},"source":["<h2 id=\"Tokenisasi-dengan-modul-NLTK\">Tokenisasi dengan modul NLTK</h2>\n","<p>NLTK dapat melakukan tokenisasi pada level kata dan pada level kalimat</p>\n","\n","<p><strong>Kelebihan</strong>:</p>\n","\n","<ol>\n","\t<li>Well established dengan dukungan bahasa yang beragam</li>\n","\t<li>Salah satu modul NLP dengan fungsi terlengkap, termasuk WordNet</li>\n","\t<li>Free dan mendapat banyak dukungan akademis.</li>\n","</ol>\n","\n","<p><strong>Kekurangan</strong>:</p>\n","\n","<ol>\n","\t<li>Murni Python: relatif lebih lambat</li>\n","</ol>\n","\n","<p><big><strong><a href=\"https://www.nltk.org/\" target=\"_blank\">https://www.nltk.org/</a></strong></big></p>\n"]},{"cell_type":"code","metadata":{"id":"3GkD7PT4GdhD","outputId":"38d481cf-5e37-4212-8d98-052c2347aedf"},"source":["# tokenisasi kata\n","from nltk import word_tokenize\n","\n","S = \"Hello, Mr. Man. He smiled!! This, i.e. that, is it.\"\n","word_token = word_tokenize(S)\n","\n","print(word_token)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Hello', ',', 'Mr.', 'Man', '.', 'He', 'smiled', '!', '!', 'This', ',', 'i.e', '.', 'that', ',', 'is', 'it', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PcHwLZExGdhG","outputId":"c48f8f28-4abe-43ba-c2e7-baf2526d7e32"},"source":["# Mengapa tidak menggunakan fungsi split dari python?? apa bedanya?\n","\n","word_split = S.split()\n","print(word_split)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Hello,', 'Mr.', 'Man.', 'He', 'smiled!!', 'This,', 'i.e.', 'that,', 'is', 'it.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DsJGDzURGdhH","outputId":"90d324a2-fb18-40ab-d3e9-691ac2bf1aa2"},"source":["# tokenisasi kalimat\n","from nltk import sent_tokenize\n","\n","sentence_token = sent_tokenize(S)\n","print(sentence_token)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Hello, Mr. Man.', 'He smiled!!', 'This, i.e.', 'that, is it.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AIasco_JGdhI"},"source":["<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 1:</font></h3>\n","\n","<ul>\n","\t<li>Apakah tanda baca seperti &quot;?&quot; atau &quot;!&quot; akan memisahkan kalimat?</li>\n","\t<li>Apakah tanda &quot;carriage return&quot;/enter/ganti baris memisahkan kalimat?</li>\n","\t<li>Apakah &quot;;&quot; memisahkan kalimat?</li>\n","\t<li>Apakah tanda dash &quot;-&quot; memisahkan kata? Dalam bahasa Indonesia/Inggris?</li>\n","</ul>\n","\n","<strong>Tips</strong>: Perhatikan bentuk <em>struktur data</em> &quot;output&quot; dari tokenisasi NLTK.<br />\n","<strong>Catatan</strong>: pindah baris di Python string bisa dilakukan dengan menggunakan symbol &quot;\\n&quot;<br />\n"]},{"cell_type":"code","metadata":{"id":"GiakVvFRGdhK"},"source":["# Kerjakan latihan 1 pada cell berikut ini\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKg5CsjqGdhL"},"source":["## Tokenisasi dengan modul Spacy\n","<strong>Kelebihan</strong>:</p>\n","<ol>\n","\t<li>Di claim lebih cepat (C-based)</li>\n","\t<li>License termasuk untuk komersil</li>\n","\t<li>Dukungan bahasa yang lebih banyak dari NLTK (termasuk bahasa Indonesia*)</li>\n","</ol>\n","\n","<p><strong>Kekurangan</strong>:</p>\n","<ol>\n","\t<li>Fungsi yang lebih terbatas (dibandingkan NLTK).</li>\n","\t<li>Karena berbasis compiler, sehingga instalasi cukup menantang.</li>\n","</ol>\n","\n","<p><big><strong><a href=\"https://spacy.io/\" target=\"_blank\">https://spacy.io/</a></strong></big></p>\n"]},{"cell_type":"code","metadata":{"id":"283fGuQtGdhN","outputId":"8908beb7-783f-4710-f96b-a171b0105379"},"source":["# Contoh tokenisasi kata menggunakan Spcay\n","import spacy\n","\n","# Loading language model\n","spacy_en = spacy.load('en')\n","\n","S = \"Hello, Mr. Man. He smiled!! This, i.e. that, is it.\"\n","tokens = spacy_en(S)\n","print( [token.text for token in tokens] )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Hello', ',', 'Mr.', 'Man', '.', 'He', 'smiled', '!', '!', 'This', ',', 'i.e.', 'that', ',', 'is', 'it', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qDEfmuP6GdhO","outputId":"b85c5fcf-31a3-4b21-bda5-4523a5d25d72"},"source":["# Contoh tokenisasi kalimat dengan Spacy\n","sentence_tokens = spacy_en(S).sents\n","print([str(sent) for sent in sentence_tokens])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Hello, Mr. Man.', 'He smiled!!', 'This, i.e. that, is it.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m4o4De78GdhP"},"source":["<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 2:</font></h3>\n","\n","<ul>\n","\t<li>Apakah hasil tokenisasi Spacy = NLTK? Mengapa?</li>\n","\t<li>Lakukan latihan seperti yang dilakukan sebelumnya dengan modul NLTK, apakah hasilnya sama dengan Spacy?</li>\n","</ul>\n","\n","<p><strong>Tips</strong>: Perhatikan bentuk <em>struktur data</em> &quot;output&quot; dari tokenisasi Spacy juga berbeda dengan NLTK.<br />\n","<strong>Catatan</strong>: Contoh sederhana ini menekankan perbedaan ilmu linguistik dan computational linguistic.</p>\n"]},{"cell_type":"code","metadata":{"id":"R1TAgGGaGdhQ"},"source":["# Kerjakan latihan 2 pada cell berikut ini\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gUv9p0QJGdhR"},"source":["## Tokenisasi dengan TextBlob\n","<strong>Kelebihan</strong>:</p>\n","<ol>\n","\t<li>Sederhana &amp; mudah untuk digunakan/pelajari.</li>\n","\t<li>Textblob objects punya behaviour/properties yang sama dengan string di Python.</li>\n","\t<li>TextBlob dibangun dari kombinasi modul NLTK dan (Clips) Pattern</li>\n","</ol>\n","\n","<p><strong>Kekurangan</strong>:</p>\n","<ol>\n","\t<li>Tidak secepat Spacy dan NLTK</li>\n","\t<li>Language Model terbatas: English, German, French</li>\n","</ol>\n","\n","<p>*Blob : Binary large Object</p>"]},{"cell_type":"code","metadata":{"id":"e_Ko97wKGdhS","outputId":"a3960e68-0f11-4bd6-95b3-46141da4cc4e"},"source":["# Contoh tokenisasi dengan TextBlob\n","from textblob import TextBlob\n","\n","T = \"Hello, Mr. Man. He smiled!! This, i.e. that, is it.\"\n","sentence_tokens = TextBlob(T).sentences\n","\n","# Tokenisasi kata\n","print(TextBlob(T).words)\n","\n","# Tokenisasi kalimat\n","print([str(sent) for sent in sentence_tokens])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Hello', 'Mr', 'Man', 'He', 'smiled', 'This', 'i.e', 'that', 'is', 'it']\n","['Hello, Mr. Man.', 'He smiled!!', 'This, i.e.', 'that, is it.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sgyUgtWZGdhT"},"source":["<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 3:</font></h3>\n","\n","<ul>\n","\t<li>Ada yang berbeda dari hasilnya?&nbsp;Apakah lebih baik seperti ini?</li>\n","</ul>\n","\n","<p><strong>Tips</strong>: TextBlob biasa digunakan untuk prototyping pada data yang tidak terlalu besar.<br />\n","<strong>Catatan</strong>: Hati-hati tipe data Blob tidak biasa (objek).</p>\n"]},{"cell_type":"code","metadata":{"id":"w6O1a7rfGdhU"},"source":["# Kerjakan latihan 3 pada cell berikut ini\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WdwNjoHbGdhV"},"source":["## Tokenisasi: language dependent dan environment dependent\n","\n","<p>Tokenization sebenarnya tidak sesederhana memisahkan berdasarkan spasi dan removing symbol. Sebagai contoh dalam bahasa Jepang/Cina/Arab suatu kata bisa terdiri dari beberapa karakter.</p>\n","\n","<p><img alt=\"\" src=\"figures/2_Tokenization_Complexity.jpg\" style=\"height:500px; width:686px\" /><br />\n","[<a href=\"http://aclweb.org/anthology/Y/Y11/Y11-1038.pdf\" target=\"_blank\"><strong>Image Source</strong></a>]</p>\n"]},{"cell_type":"markdown","metadata":{"id":"BDkd2CQkGdhW"},"source":["__Bagaimana untuk data yang punya karakteristik tertentu seperti Twitter?__\n","__Apakah bisa menggunakan modul tokenisasi yang telah tersedia?__"]},{"cell_type":"code","metadata":{"id":"rHpcLCQnGdhX","outputId":"97e0db57-4aba-4af1-8995-b2748d21dab6"},"source":["# Contoh Tokenizer untuk twitter\n","from nltk.tokenize import TweetTokenizer\n","\n","Tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n","tweet = \"@stki I am so happpppppppy, supeeeer happpy :) #imsohappy #happy\"\n","print(Tokenizer.tokenize(tweet))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['I', 'am', 'so', 'happpy', ',', 'supeeer', 'happpy', ':)', '#imsohappy', '#happy']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PR8qjXXVGdhY","outputId":"01fbc1da-046d-4370-b3c3-805f06f79d76"},"source":["import itertools \n","\n","tweet = \"@stki I am so supeeeeeeer\"\n","\n","# Menghilangkan double karakter\n","tweet_clear = ''.join(''.join(s)[:1] for _, s in itertools.groupby(tweet))\n","print(tweet_clear)\n","\n","# NOTES: untuk beberapa data spesifik seperti data bioinformatics, cryptography,\n","# twitter, dst dibutuhkan tokenizer custom untuk dapat memenuhi kebutuha"],"execution_count":null,"outputs":[{"output_type":"stream","text":["@stki I am so super\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZrF6c6VgGdhZ"},"source":["## Tokenisasi (NLP) Bahasa Indonesia:\n","\n","<p>NLTK belum support Bahasa Indonesia, bahkan module NLP Python yang support bahasa Indonesia secara umum masih sangat langka. Beberapa <u><strong>resources </strong></u>yang dapat digunakan:</p>\n","\n","<ol>\n","\t<li><strong><a href=\"https://github.com/kirralabs/indonesian-NLP-resources\" target=\"_blank\">KirraLabs</a></strong>: Mix of NLP-TextMining resources</li>\n","\t<li><strong><a href=\"https://pypi.python.org/pypi/Sastrawi/1.0.1\" target=\"_blank\">Sastrawi 1.0.1</a>:</strong>&nbsp;untuk &quot;stemming&quot; &amp;&nbsp;<strong><a href=\"https://devtrik.com/python/stopword-removal-bahasa-indonesia-python-sastrawi/\" target=\"_blank\">stopwords&nbsp;</a></strong>bahasa Indonesia.</li>\n","\t<li><strong><a href=\"http://stop-words-list-bahasa-indonesia.blogspot.co.id/2012/09/daftar-kata-dasar-bahasa-indonesia.html\" target=\"_blank\">Daftar Kata Dasar Indonesia</a></strong>:&nbsp;Bisa di load sebagai dictionary di Python</li>\n","\t<li><strong><a href=\"https://id.wiktionary.org/wiki/Wiktionary:ProyekWiki_bahasa_Indonesia/Daftar_kata\" target=\"_blank\">Wiktionary</a></strong>: ProyekWiki bahasa Indonesia [termasuk Lexicon]</li>\n","\t<li><a href=\"http://wn-msa.sourceforge.net/\" target=\"_blank\"><strong>WordNet Bahasa Indonesia</strong></a>: Bisa di load&nbsp;sebagai dictionary (atau NLTK<em>*</em>) di Python.</li>\n","\t<li><strong><a href=\"http://kakakpintar.com/daftar-kata-baku-dan-tidak-baku-a-z-dalam-bahasa-indonesia/\" target=\"_blank\">Daftar Kata Baku-Tidak Baku</a></strong>: Bisa di load sebagai dictionary di Python.</li>\n","\t<li><strong><a href=\"https://spacy.io/\" target=\"_blank\">Spacy</a></strong>: Cepat/efisien, MIT License, tapi language model Indonesia masih terbatas.</li>\n","\t<li><a href=\"http://ufal.mff.cuni.cz/udpipe\" target=\"_blank\"><strong>UdPipe</strong></a>: Online request &amp; restricted license (support berbagai bahasa -&nbsp;pemrograman).</li>\n","</ol>"]},{"cell_type":"code","metadata":{"id":"o3HzeEHbGdhc","outputId":"9f19a392-5f57-420e-bb70-db1129d63a47"},"source":["# Contoh Tokenisasi dalam bahasa Indonesia dengan Spacy\n","from spacy.lang.id import Indonesian\n","\n","# load language model bahasa Indonesia\n","spacy_id = Indonesian()\n","\n","S = 'Sore itu, Hamzah melihat kupu-kupu di taman. Ibu membeli oleh-oleh di pasar'\n","word_token = spacy_id(S)\n","print([token.text for token in word_token])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Sore', 'itu', ',', 'Hamzah', 'melihat', 'kupu-kupu', 'di', 'taman', '.', 'Ibu', 'membeli', 'oleh-oleh', 'di', 'pasar']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pYJUtQDmGdhd","outputId":"e00d1c77-7f60-465e-dd8a-7dc3e9fd80ee"},"source":["# Jika menggunakan Language model English:\n","word_token_en = spacy_en(S)\n","print([token.text for token in word_token_en])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Sore', 'itu', ',', 'Hamzah', 'melihat', 'kupu', '-', 'kupu', 'di', 'taman', '.', 'Ibu', 'membeli', 'oleh', '-', 'oleh', 'di', 'pasar']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DTdYrRpxGdhe"},"source":["<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 4:</font></h3>\n","\n","<ul>\n","\t<li>Apakah ada perbedaan apabila menggunakan language model yang berbeda?</li>\n","    <li>Bagaimana jika melakukan tokenisasi Bahasa Indonesia dengan NLTK? Apakah hasilnya sama dengan Spacy?\n","</ul>\n","\n"]},{"cell_type":"code","metadata":{"id":"zYhrGfOqGdhf"},"source":["# Kerjakan Latihan 4 pada cell berikut ini\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YHcd3fiSGdhg"},"source":["## Casefolding\n","\n","<p> Casefolding dilakukan untuk merubah karakter ke dalam huruf besar (uppercase) atau huruf kecil (lowercase) </p>\n","\n","<ul>\n","\t<li>Untuk menganalisa makna (<em>semantic</em>) dari suatu (frase) kata dan mencari informasi dalam proses textmining, seringnya kita tidak membutuhkan informasi huruf besar/kecil dari kata&nbsp;tersebut.</li>\n","    <li>Casefolding dapat dilakukan dengan efisien tanpa melalui proses tokenisasi</li>\n","\t<li>Namun, bergantung pada analisa teks yang akan digunakan pengguna harus berhati-hati dengan urutan proses (pipelining) dalam preprocessing. </li>\n","</ul>"]},{"cell_type":"code","metadata":{"id":"9Eo1d58WGdhg","outputId":"df1609c0-6a36-46aa-fb70-07303433995d"},"source":["# Contoh casefolding\n","S = \"Hi there!, I am a student. Nice to meet you :)\"\n","print(S.lower())\n","print(S.upper())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["hi there!, i am a student. nice to meet you :)\n","HI THERE!, I AM A STUDENT. NICE TO MEET YOU :)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rog6T5AeGdhh"},"source":["<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 5:</font></h3>\n","\n","<ul>\n","\t<li>Temukan minimal 2 pengecualian dimana huruf besar dan kecil mempengaruhi makna dalam pemrosesan teks</li>\n","    <li>Mengapa casefolding dapat dilakukan secara efisien tanpa melalui tahap tokenisasi?</li>\n","    <li>Berikan contoh pengaruh dari urutan proses dalam preprocessing yang berpengaruh terhadap hasil preprocessing </li>\n","        \n","</ul>\n","\n"]},{"cell_type":"code","metadata":{"id":"XNzLEaqMGdhh"},"source":["# Kerjakan latihan 5 pada cell berikut ini\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2FwO1Ta-Gdhi"},"source":["## Stemming dan Lemmatization\n","\n","<ol>\n","\t<li>\n","\t<p><strong>Stemmer</strong>&nbsp;akan menghasilkan sebuah bentuk kata yang disepakati oleh suatu sistem tanpa mengindahkan konteks kalimat. Syaratnya beberapa kata dengan makna serupa hanya perlu dipetakan secara konsisten ke sebuah kata baku.&nbsp;Banyak digunakan di IR &amp;&nbsp;komputasinya relatif sedikit. Biasanya dilakukan dengan menghilangkan imbuhan (suffix/prefix).</p>\n","\t</li>\n","\t<li>\n","\t<p><strong>lemmatisation</strong> akan menghasilkan kata baku (dictionary word) dan bergantung konteks.</p>\n","\t</li>\n","\t<li>\n","\t<p>Lemma &amp; stemming bisa jadi sama-sama menghasilkan suatu akar kata (root word). Misal : <em>Melompat </em>==&gt; <em>lompat</em></p>\n","\t</li>\n","</ol>"]},{"cell_type":"markdown","metadata":{"id":"spXPmefnGdhi"},"source":["<p><strong>Mengapa melakukan Stemming &amp; Lemmatisasi</strong>?</p>\n","\n","<ol>\n","\t<li>Sering digunakan di IR (Information Retrieval) agar ketika seseorang mencari kata tertentu, maka seluruh kata yang terkait juga diikutsertakan.<br />\n","\tMisal:&nbsp;<em>organize</em>,&nbsp;<em>organizes</em>, and&nbsp;<em>organizing&nbsp;</em>&nbsp;dan&nbsp;<em>democracy</em>,&nbsp;<em>democratic</em>, and&nbsp;<em>democratization</em>.</li>\n","\t<li>Di Text Mining Stemming dan Lemmatisasi akan mengurangi dimensi (mengurangi variasi morphologi), yang terkadang akan meningkatkan akurasi.</li>\n","\t<li>Tapi di IR efeknya malah berkebalikan: <strong><font color=\"blue\">meningkatkan recall, tapi menurunkan akurasi&nbsp;</font></strong>[<a href=\"https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\" target=\"_blank\"><strong>Link</strong></a>]. Contoh: kata&nbsp;<em>operate, operating, operates, operation, operative, operatives, dan operational</em>&nbsp;jika di stem menjadi <em>operate</em>, maka ketika seseorang mencari &quot;<em>operating system</em>&quot;, maka entry seperti&nbsp;<em>operational and research</em> dan&nbsp;<em>operative and dentistry</em>&nbsp;akan muncul sebagai entry dengan relevansi yang cukup tinggi.</li>\n","</ol>\n"]},{"cell_type":"markdown","metadata":{"id":"e2fX_F8VGdhi"},"source":["__Stemming tidak perlu \"benar\", hanya perlu konsisten__"]},{"cell_type":"markdown","metadata":{"id":"OW62Po_kGdhj"},"source":["## NLTK"]},{"cell_type":"code","metadata":{"id":"rToCTObtGdhj","outputId":"24c0864d-a8e4-430a-d450-44848c2ac7de"},"source":["# Contoh Stemming di NLTK\n","from nltk.stem.lancaster import LancasterStemmer\n","from nlalltk.stem.porter import PorterStemmer\n","from nltk.stem.snowb import SnowballStemmer\n","\n","S = 'presumably I would like to MultiPly my provision, saying tHat without crYing'\n","print('Sentence: ',S)\n","\n","stemmer_list = [LancasterStemmer, PorterStemmer, SnowballStemmer] \n","names = ['Lancaster', 'Porter', 'SnowBall']\n","for stemmer_name,stem in zip(names,stemmer_list):\n","    if stemmer_name == 'SnowBall':\n","        st = stem('english')\n","    else:\n","        st = stem()\n","    print(stemmer_name,': ',' '.join(st.stem(s) for s in S.split()))\n","# perhatikan, kita tidak melakukan case normalization (lowercase) \n","# Hasil stemming bisa tidak bermakna"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence:  presumably I would like to MultiPly my provision, saying tHat without crYing\n","Lancaster :  presum i would lik to multiply my provision, say that without cry\n","Porter :  presum I would like to multipli my provision, say that without cri\n","SnowBall :  presum i would like to multipli my provision, say that without cri\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ww2jyHXqGdhk","outputId":"68eb18f7-61fa-40cd-e3ea-11326e51640f"},"source":["# Contoh Lemmatizer di NLTK\n","from nltk.stem import WordNetLemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","S = \"apples and oranges are similar. boots and hippos aren't, don't you think?\"\n","print('Sentence: ', S)\n","print('Lemmatize: ',' '.join(lemmatizer.lemmatize(s) for s in S.split()))\n","# Lemma case sensitive. Dengan kata lain string harus diubah ke dalam bentuk huruf kecil (lower case)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sentence:  apples and oranges are similar. boots and hippos aren't, don't you think?\n","Lemmatize:  apple and orange are similar. boot and hippo aren't, don't you think?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NPZ1opHHGdhl","outputId":"6f8a92d6-f159-49dd-888a-fe7671bb9015"},"source":["# Lemmatizer menggunakan informasi pos. \"pos\" (part-of-speech) akan dibahas di segmen berikutnya\n","print(lemmatizer.lemmatize(\"better\", pos=\"a\")) # adjective\n","print(lemmatizer.lemmatize(\"better\", pos=\"v\")) # verb"],"execution_count":null,"outputs":[{"output_type":"stream","text":["good\n","better\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8ISmjsdMGdhl"},"source":["## TextBlob"]},{"cell_type":"code","metadata":{"id":"qaZa3o97Gdhm","outputId":"a9c67489-dac1-4247-bf31-63023ab94c2f"},"source":["# Contoh TextBlob Stemming & Lemmatizer\n","from textblob import Word\n","# Stemming\n","print(\"Stem: \", Word('running').stem()) # menggunakan NLTK Porter stemmer\n","\n","# Lemmatizer\n","print(\"Lemmatize: \", Word('went').lemmatize('v'))\n","\n","# default Noun, plural akan menjadi singular dari akar katanya\n","# Juga case sensitive"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Stem:  run\n","Lemmatize:  go\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"M-GaTcnsGdhm"},"source":["## Spacy"]},{"cell_type":"code","metadata":{"id":"Sd2Oa6XWGdhn","outputId":"0cfeda7f-7d3d-4788-f018-9a051a2511bd"},"source":["# Spacy Lemmatizer English\n","sent = \"I am sure Apples and oranges are similar. Boots and hippos aren't, don't you think?\"\n","sent_token = spacy_en(sent)\n","print( ' '.join( s.lemma_ for s in sent_token ) )\n","# HATI-HATI dengan lemma \"I\" dan \"you\" di Spacy!!!..."],"execution_count":null,"outputs":[{"output_type":"stream","text":["-PRON- be sure apples and orange be similar . boot and hippo be not , do not -PRON- think ?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JVqT805NGdho","outputId":"4e82e327-393e-4013-806d-1032cda196f7"},"source":["# Spacy Lemmatizer Indonesia\n","I = \"perayaan itu berbarengan dengan saat kita bepergian ke Jogjakarta\"\n","idn = spacy_id(I)\n","print( ' '.join( k.lemma_ for k in idn ) )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["raya itu bareng dengan saat kita pergi ke Jogjakarta\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nTX9OEwhGdho","outputId":"1c6c15cc-0a3f-4dec-cf26-2d736769508e"},"source":["# Perhatikan output berikut (hati-hati inkonsistensi)\n","print([k.lemma_ for k in spacy_id(\"Perayaan Bepergian\")])\n","\n","# bagaimana dengan Spacy stemmer??\n","# Spacy belum support stemmer"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['Perayaan', 'Bepergian']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UwunTiGrGdhp"},"source":["## Sastrawi"]},{"cell_type":"code","metadata":{"id":"9IuF7tEOGdhq","outputId":"708dabd3-6dcb-4974-ba41-6a9fef947c7f"},"source":["# Lemmatizer dengan Sastrawi\n","from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n","stemmer = StemmerFactory().create_stemmer()\n","\n","I = \"perayaan itu berbarengan dengan saat kita bepergian ke Makassar\"\n","print(stemmer.stem(I))\n","print(stemmer.stem(\"Perayaan Bepergian Menyuarakan\"))\n","# Ada beberapa hal yang berbeda antara Sastrawi dan modul-modul diatas.\n","# Apa sajakah?"],"execution_count":null,"outputs":[{"output_type":"stream","text":["raya itu bareng dengan saat kita pergi ke makassar\n","raya pergi suara\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nAuO4vnPGdhr"},"source":["<h3 id=\"Tips:\">Tips:</h3>\n","\n","<ul>\n","\t<li>Secara umum &#39;biasanya&#39; di Text Mining yang kita butuhkan hanyalah <strong><font color=\"blue\">Lemma</font></strong>.</li>\n","\t<li>&quot;Kecuali&quot; di aplikasi IR, spelling correction, variasi kata, clustering, atau terkadang klasifikasi. Pada aplikasi-aplikasi tersebut stemming terkadang lebih diinginkan.</li>\n","\t<li>Stemming jauh lebih cepat, tapi tidak selalu tersedia di modul NLP.</li>\n","\t<li>Beberapa algoritma tertentu membutuhkan tanda &quot;.&quot; dan &quot;,&quot; : contohnya untuk document summarization di textRank.</li>\n","\t<li>&quot;_&quot; juga biasa digunakan untuk menyatakan frase kata di representasi n-grams (misal &quot;buah_tangan&quot;).</li>\n","\t<li>Stemming juga digunakan pada Word Sense Disambiguation (WSD)</li>\n","</ul>\n","\n","<h3 id=\"Diskusi:\">Diskusi:</h3>\n","\n","<ul>\n","\t<li>Untuk menghemat storage database, apakah sebaiknya kita menyimpan saja hasil preprocessed texts/documents?</li>\n","</ul>\n"]},{"cell_type":"markdown","metadata":{"id":"SVwGUT8iGdhr"},"source":["## Part-of-Speech (POS) tag\n","\n","<p> POS tagging merupakan proses pemberian tanda berupa kelas kata pada setiap kata yang terdapat di dalam corpus.</p>\n","\n","<p><img alt=\"\" src=\"figures/2_parts-of-speech-chart.jpg\" style=\"height:400px; width:404px\" /></p>\n","<p>[<a href=\"https://www.paperrater.com/page/parts-of-speech\" target=\"_blank\">image source</a>]</p>"]},{"cell_type":"code","metadata":{"id":"YlAoEM0fGdhs","outputId":"f3c71518-af9e-41bd-92aa-63acd33c321a"},"source":["# Contoh POS tags dengan NLTK (bahasa Inggris)\n","from nltk import pos_tag\n","S = 'I am currently learning NLP in English, but if possible I want to know NLP in Indonesian language too'\n","\n","tokens = word_tokenize(S)\n","print(pos_tag(tokens))\n","# Tidak lagi hanya 9 macam tags seperti yang dibahas ahli bahasa (linguist)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('I', 'PRP'), ('am', 'VBP'), ('currently', 'RB'), ('learning', 'VBG'), ('NLP', 'NNP'), ('in', 'IN'), ('English', 'NNP'), (',', ','), ('but', 'CC'), ('if', 'IN'), ('possible', 'JJ'), ('I', 'PRP'), ('want', 'VBP'), ('to', 'TO'), ('know', 'VB'), ('NLP', 'NNP'), ('in', 'IN'), ('Indonesian', 'JJ'), ('language', 'NN'), ('too', 'RB')]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jmnZ1JmFGdht"},"source":["### Daftar POS tag NLTK:\n","\n","<img alt=\"\" src=\"figures/2_post_tags_NLTK.png\" style=\"height:400px; width:516px\" /></h3>\n","\n","<p>[<a href=\"http://gitqwerty777.github.io/natural-language-processing/\" target=\"_blank\">image source</a>]</p>"]},{"cell_type":"code","metadata":{"id":"dasYYZLLGdht","outputId":"e699844b-af63-41fb-d7f9-dee1206a19f4"},"source":["# Contoh POS tag dengan TextBlob pada bahasa Inggris\n","for word, pos in TextBlob(T).tags:\n","    print(word, pos, end=', ')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Hello NNP, Mr. NNP, Man NNP, He PRP, smiled VBD, This DT, i.e NN, that DT, is VBZ, it PRP, "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tz5jRrXyGdhu","outputId":"df0f43c3-fe9a-4bfb-a246-8c2ffc3df23e"},"source":["# Contoh POS tag dengan Spacy pada bahasa Inggris\n","tokens = spacy_en(T)\n","for token in tokens:\n","    print(token,token.tag_, end =', ')\n","    \n","# Spacy belum support POS tag untuk bahasa Indonesia"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Hello UH, , ,, Mr. NNP, Man NNP, . ., He PRP, smiled VBD, ! ., ! ., This DT, , ,, i.e. FW, that DT, , ,, is VBZ, it PRP, . ., "],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9yOD2-8tGdhv","outputId":"35c45dcf-7251-4589-b93b-5daceef61471"},"source":["# Untuk mengetahui arti dari POS tag pada Spacy dapat menggunakan perintah \"explain\"\n","spacy.explain('RB')\n","# Daftar Lengkap: https://spacy.io/api/annotation#pos-tagging"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'adverb'"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"Gi-9cierGdhw","outputId":"40f09d46-ee92-4bd6-e610-09acbe809d45"},"source":["# POS tag bahasa Indonesia dengan NLTK\n","# https://yudiwbs.wordpress.com/2018/02/20/pos-tagger-bahasa-indonesia-dengan-pytho/\n","from nltk.tag import CRFTagger\n","ct = CRFTagger()\n","ct.set_model_file('data/all_indo_man_tag_corpus_model.crf.tagger')\n","\n","hasil = ct.tag_sents([['Saya','bekerja','di','Bandung']])\n","print(hasil)\n","# Hati-hati dengan struktur data inputnya"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[('Saya', 'PRP'), ('bekerja', 'VB'), ('di', 'IN'), ('Bandung', 'NNP')]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JTjcdke8Gdhw"},"source":["<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 6:</font></h3>\n","\n","<ul>\n","\t<li>Kapan harus melakukan POS tagging pada tahap preprocessing?</li>\n","    <li>Buatlah contoh hasi dari POS tag dengan hanya mengambil kata yang memiliki tag NOUN (*), dan berikan contoh kasus penggunaannya?</li>\n","    <li>Buatlah contoh hasil dari POS tag yang telah ditambahkan pada setiap kata dalam suatu kalimat dengan menggunakan NLTK (**)</li>\n","        \n","</ul>\n","\n","<p>(*) <strong>Input</strong>: \"The tiger (Panthera tigris) is the largest extant cat species and a member of the genus Panthera. It is most recognisable for its dark vertical stripes on orange-brown fur with a lighter underside. It is an apex predator, primarily preying on ungulates such as deer and wild boar.\"</p>\n","<p>(**)</p> \n","<p> <strong>Input</strong>: \"I am currently learning NLP in English, but if possible I want to know NLP in Indonesian language too\"</p>\n","<p> <strong>Expected output</strong>: \"I_PRP am_VBP currently_RB learning_VBG NLP_NNP in_IN English_NNP ,_, but_CC if_IN possible_JJ I_PRP want_VBP to_TO know_VB NLP_NNP in_IN Indonesian_JJ language_NN too_RB\"\n"]},{"cell_type":"code","metadata":{"id":"Tk6gqjD1Gdhx"},"source":["# Kerjakan latihan 6 pada cell berikut ini\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M0bcli9SGdhy"},"source":["## Stopword removal\n","\n","<p> Stopword removal merupakan salah satu cara untuk melakukan normalisasi pada level kata </p>\n","<p><u>Di Text Mining</u> kata-kata yang <strong>sering muncul </strong>(dan jarang sekali muncul) memiliki sedikit sekali informasi (signifikansi) terhadap model (machine learning) yang digunakan. Hal ini di karenakan kata-kata tersebut muncul di semua kategori (di permasalahan klasifikasi) atau di semua cluster (di permasalahan pengelompokan/clustering). Kata-kata yang sering muncul ini biasa disebut &quot;StopWords&quot;. Stopwords berbeda-beda bergantung dari Bahasa dan Environment (aplikasi)-nya.<br />\n","<strong>Contoh</strong>:<br />\n","\n","<ul>\n","\t<li>Stopwords bahasa Inggris: am, is, are, do, the, of, etc.</li>\n","\t<li>Stopwords bahasa Indonesia: adalah, dengan, yang, di, ke, dsb</li>\n","\t<li>Stopwords twitter: RT, ...</li>\n","</ul>"]},{"cell_type":"code","metadata":{"id":"1LhNtKI5Gdhy","outputId":"cf7e3541-3d3a-4b1d-c0d3-3fb856ca4092"},"source":["# Contoh stopword dari NLTK\n","from nltk.corpus import stopwords\n","\n","nltk_stw_en = stopwords.words('english')\n","print(nltk_stw_en[:10])\n","\n","nltk_stw_id = stopwords.words('indonesian')\n","print(nltk_stw_id[:10])\n","\n","# Lsit stopword dapat ditambahkan dan dikurangi sesuai dengan kebutuhan"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n","['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zAvt50LIGdhz","outputId":"6caf1bc9-4583-491c-d0db-403fafa5cb91"},"source":["#contoh stopword dari Sastrawi pada bahasa Indonesia\n","from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n","\n","factory = StopWordRemoverFactory()\n","sastrawi_stw_id = factory.get_stop_words()\n","print(sastrawi_stw_id[:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['yang', 'untuk', 'pada', 'ke', 'para', 'namun', 'menurut', 'antara', 'dia', 'dua']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"65AwqowSGdhz"},"source":["# Tips:\n","# selalu rubah list stopwords ke bentuk set, karena di Python jauh lebih cepat untuk cek existence di set ketimbang list\n","nltk_stw_en = set(nltk_stw_en)\n","nltk_stw_id = set(nltk_stw_id)\n","sastrawi_stw_id = set(sastrawi_stw_id)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uD2PwuQBGdh0"},"source":["<h3 id=\"Latihan:\"><font color=\"blue\">Latihan 7:</font></h3>\n","\n","<p> Lakukan stopword removal pada contoh paragraf berikut ini: </p>\n","<p> \"Siti Nurbaya adalah sebuah novel Indonesia yang ditulis oleh Marah Rusli. Novel ini diterbitkan oleh Balai Pustaka, penerbit nasional negeri Hindia Belanda, pada tahun 1922.\" </p>\n"]},{"cell_type":"code","metadata":{"id":"PVa7Im8nGdh0"},"source":["# Kerjakan latihan 7 pada cell berikut ini\n"],"execution_count":null,"outputs":[]}]}